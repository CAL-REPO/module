# Crawl Utils Configuration Examples

ì´ ë””ë ‰í† ë¦¬ëŠ” `crawl_utils` ëª¨ë“ˆì˜ ì„¤ì • íŒŒì¼ ì˜ˆì œë¥¼ í¬í•¨í•©ë‹ˆë‹¤.

## ğŸ“ íŒŒì¼ êµ¬ì¡°

```
config/
â”œâ”€â”€ README.md                # ì´ íŒŒì¼
â”œâ”€â”€ crawl.yaml               # ê¸°ë³¸ ì„¤ì •
â”œâ”€â”€ crawl_simple.yaml        # ê°„ë‹¨í•œ ì˜ˆì œ
â””â”€â”€ crawl_full.yaml          # ì „ì²´ ì˜µì…˜ ì˜ˆì œ
```

## ğŸ¯ ì‚¬ìš© ë°©ë²•

### 1. Simple ë²„ì „ (ê¶Œì¥)

ìì£¼ ì‚¬ìš©í•˜ëŠ” ì˜µì…˜ë§Œ í¬í•¨í•œ ê°„ë‹¨í•œ ì˜ˆì œì…ë‹ˆë‹¤.

```python
from crawl_utils import FirefoxWebDriver, run_sync_crawl

# WebDriver ì„¤ì •
driver_config = {
    "headless": True,
    "window_size": (1920, 1080)
}

# ë™ê¸° ë°©ì‹ìœ¼ë¡œ í¬ë¡¤ë§ ì‹¤í–‰
with FirefoxWebDriver(driver_config) as driver:
    items = run_sync_crawl(
        "crawl_utils/config/crawl_simple.yaml",
        driver,
        max_pages=5
    )
    print(f"Crawled {len(items)} items")
```

### 2. Full ë²„ì „

ëª¨ë“  ê°€ëŠ¥í•œ ì˜µì…˜ì„ í™•ì¸í•˜ê³  ì‹¶ì„ ë•Œ ì°¸ê³ í•˜ì„¸ìš”.

```python
from crawl_utils import SyncCrawlRunner, FirefoxWebDriver, CrawlPolicy
from cfg_utils import ConfigLoader

# YAMLì—ì„œ ì •ì±… ë¡œë“œ
loader = ConfigLoader("crawl_utils/config/crawl_full.yaml")
policy = loader.as_model(CrawlPolicy, section="crawl")

# í¬ë¡¤ëŸ¬ ì‹¤í–‰
with FirefoxWebDriver(driver_config) as driver:
    runner = SyncCrawlRunner(policy)
    items = runner.run_crawl(driver, max_pages=10)
```

### 3. Runtime Override

YAML ì„¤ì •ì„ ê¸°ë³¸ìœ¼ë¡œ í•˜ê³  íŠ¹ì • ê°’ë§Œ ëŸ°íƒ€ì„ì— ë³€ê²½:

```python
from cfg_utils import ConfigLoader

# YAML ë¡œë“œ
loader = ConfigLoader("crawl_utils/config/crawl_simple.yaml")
policy = loader.as_model(CrawlPolicy, section="crawl")

# ëŸ°íƒ€ì„ì— ì„¤ì • ë³€ê²½
policy.execution_mode = "async"
policy.concurrency = 8
policy.navigation.max_pages = 20

# ì‹¤í–‰
runner = SyncCrawlRunner(policy)
items = runner.run_crawl(driver)
```

## ğŸ“‹ ì£¼ìš” ì„¤ì • ì„¤ëª…

### Navigation (í˜ì´ì§€ ìˆœíšŒ)

```yaml
navigation:
  base_url: "https://example.com/products"
  url_template: "https://example.com/products?page={page}"
  page_param: "page"
  start_page: 1
  max_pages: 10
  params:
    category: "electronics"
```

### Scroll (ìŠ¤í¬ë¡¤ ì „ëµ)

```yaml
scroll:
  strategy: "infinite"      # none | paginate | infinite
  max_scrolls: 10
  scroll_pause_sec: 1.5
```

### Extractor (ë°ì´í„° ì¶”ì¶œ)

```yaml
extractor:
  type: "dom"              # dom | js | api
  item_selector: ".product-item"
```

### Wait (ë¡œë”© ëŒ€ê¸°)

```yaml
wait:
  hook: "css"              # none | css | xpath
  selector: ".product-item"
  timeout_sec: 10.0
  condition: "visibility"  # presence | visibility
```

### Normalization (ì •ê·œí™”)

```yaml
normalization:
  rules:
    - kind: "image"
      source: "img.src"
      static_section: "products"
      name_template: "product_{index}"
      extension: ".jpg"
      explode: true
```

### Storage (ì €ì¥)

```yaml
storage:
  image:
    base_dir: "output/crawl/images"
    name_template: "{section}_{index}"
    ensure_unique: true
  
  text:
    base_dir: "output/crawl/texts"
    name_template: "{section}_{index}"
```

### Execution (ì‹¤í–‰ ëª¨ë“œ)

```yaml
execution_mode: "async"    # async | sync
concurrency: 4             # async ëª¨ë“œì—ì„œë§Œ
retries: 2
retry_backoff_sec: 1.0
```

## ğŸ”„ ì‹¤í–‰ ëª¨ë“œ

### Async Mode (ê¸°ë³¸, ê¶Œì¥)

ê³ ì„±ëŠ¥, ë³µì¡í•œ íŒŒì´í”„ë¼ì¸ì— ì í•©:

```yaml
execution_mode: "async"
concurrency: 4
```

**ì¥ì :**
- ì—¬ëŸ¬ í˜ì´ì§€ ë™ì‹œ ì²˜ë¦¬
- ë„¤íŠ¸ì›Œí¬ ëŒ€ê¸° ì‹œê°„ ìµœì†Œí™”
- ëŒ€ëŸ‰ í¬ë¡¤ë§ì— íš¨ìœ¨ì 

**ì‚¬ìš© ì˜ˆ:**
```python
# ìë™ìœ¼ë¡œ ë¹„ë™ê¸° ì‹¤í–‰ë¨
runner = SyncCrawlRunner(policy)  # ë‚´ë¶€ì—ì„œ asyncio.run() ì‚¬ìš©
items = runner.run_crawl(driver)
```

### Sync Mode

ê°„ë‹¨í•œ ìŠ¤í¬ë¦½íŠ¸, Jupyter ë…¸íŠ¸ë¶ì— ì í•©:

```yaml
execution_mode: "sync"
```

**ì¥ì :**
- ì´í•´í•˜ê¸° ì‰¬ìš´ ìˆœì°¨ ì‹¤í–‰
- ë””ë²„ê¹… ìš©ì´
- ì‘ì€ ê·œëª¨ í¬ë¡¤ë§ì— ì í•©

**ì‚¬ìš© ì˜ˆ:**
```python
# ìˆœì°¨ì ìœ¼ë¡œ í•œ í˜ì´ì§€ì”© ì²˜ë¦¬
runner = SyncCrawlRunner(policy)
items = runner.run_crawl(driver, max_pages=3)
```

## ğŸ’¡ íŒ

### 1. ìµœì†Œ ì„¤ì •

í•„ìˆ˜ í•­ëª©ë§Œ ì„¤ì •í•˜ê³  ë‚˜ë¨¸ì§€ëŠ” ê¸°ë³¸ê°’ ì‚¬ìš©:

```yaml
crawl:
  navigation:
    base_url: "https://example.com"
  
  storage:
    image:
      base_dir: "output/images"
  
  execution_mode: "sync"
```

### 2. ë¬´í•œ ìŠ¤í¬ë¡¤ í˜ì´ì§€

Instagram, Facebook ë“±ì˜ ë¬´í•œ ìŠ¤í¬ë¡¤:

```yaml
scroll:
  strategy: "infinite"
  max_scrolls: 20
  scroll_pause_sec: 2.0

wait:
  hook: "css"
  selector: ".loading-spinner"
  condition: "visibility"
```

### 3. API ê¸°ë°˜ ì¶”ì¶œ

JavaScriptë¡œ API í˜¸ì¶œ:

```yaml
extractor:
  type: "js"
  js_snippet: |
    const response = await fetch('/api/products');
    return await response.json();
```

### 4. ì„¹ì…˜ë³„ ê·¸ë£¹í•‘

ì¹´í…Œê³ ë¦¬ë³„ë¡œ íŒŒì¼ ë¶„ë¥˜:

```yaml
normalization:
  rules:
    - kind: "image"
      source: "img.src"
      section_field: ".category"  # ì¹´í…Œê³ ë¦¬ë³„ë¡œ ì„¹ì…˜ ìƒì„±
      name_template: "{section}_{index}"
```

## ğŸ“š ê´€ë ¨ ë¬¸ì„œ

- [crawl_utils README](../README.md)
- [CrawlPolicy ì •ì˜](../core/policy.py)
- [SyncCrawlRunner êµ¬í˜„](../services/sync_runner.py)

## âš ï¸ ì£¼ì˜ì‚¬í•­

1. **execution_mode**: async ëª¨ë“œê°€ ê¸°ë³¸ì´ì§€ë§Œ, ê°„ë‹¨í•œ ìŠ¤í¬ë¦½íŠ¸ëŠ” sync ê¶Œì¥
2. **concurrency**: ë„ˆë¬´ ë†’ìœ¼ë©´ ì„œë²„ ë¶€í•˜ ì¦ê°€ (2-8 ê¶Œì¥)
3. **retries**: API ì œí•œì´ ìˆëŠ” ì‚¬ì´íŠ¸ëŠ” ì¬ì‹œë„ ì¤„ì´ê¸°
4. **selector**: CSS ì…€ë ‰í„° ì •í™•ì„±ì´ í¬ë¡¤ë§ ì„±ê³µì˜ í•µì‹¬

## ğŸ¯ ë§ˆì´ê·¸ë ˆì´ì…˜ ê°€ì´ë“œ

### ê¸°ì¡´ ë°©ì‹

```python
# ì§ì ‘ íŒŒì´í”„ë¼ì¸ êµ¬ì„±
navigator = Navigator(...)
extractor = Extractor(...)
normalizer = Normalizer(...)
# ...
```

### ìƒˆ ë°©ì‹ (YAML ì‚¬ìš©)

```python
# YAMLë¡œ ëª¨ë“  ì„¤ì • ê´€ë¦¬
items = run_sync_crawl("config/crawl.yaml", driver)
```

### ì£¼ìš” ë³€ê²½ì‚¬í•­

1. **ì„¤ì • íŒŒì¼í™”**: ì½”ë“œì™€ ì„¤ì • ë¶„ë¦¬
2. **ì‹¤í–‰ ëª¨ë“œ**: sync/async ì„ íƒ ê°€ëŠ¥
3. **í¸ì˜ í•¨ìˆ˜**: `run_sync_crawl()` ì¶”ê°€
4. **íƒ€ì… ì•ˆì „ì„±**: Pydantic Policyë¡œ ê²€ì¦
