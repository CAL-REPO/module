# í”„ë¡œì íŠ¸ ì¬êµ¬ì¡°í™” ê³„íš

## ğŸ“‹ í˜„ì¬ ë¬¸ì œì 

### 1ï¸âƒ£ **ì—­í•  ë¶ˆëª…í™•**
- `scripts/` í´ë”ì— ë©”ì¸ ìŠ¤í¬ë¦½íŠ¸, í…ŒìŠ¤íŠ¸, ìœ í‹¸ë¦¬í‹°ê°€ í˜¼ì¬
- Service/Adapter/Runner êµ¬ë¶„ ì—†ìŒ
- ì¬ì‚¬ìš© ê°€ëŠ¥í•œ ì»´í¬ë„ŒíŠ¸ê°€ ìŠ¤í¬ë¦½íŠ¸ì— ë¬¶ì—¬ìˆìŒ

### 2ï¸âƒ£ **íŒŒì¼ ë¶„ë¥˜**

#### í˜„ì¬ `scripts/` ë‚´ì—­:
```
ğŸ“ scripts/
â”œâ”€â”€ ğŸš€ ë©”ì¸ ìŠ¤í¬ë¦½íŠ¸ (ì‹¤í–‰ìš©)
â”‚   â”œâ”€â”€ xloto.py              # OTO ë©”ì¸
â”‚   â”œâ”€â”€ xlcrawl2.py           # Excel í¬ë¡¤ë§ ë©”ì¸
â”‚   â””â”€â”€ oto.py                # OTO êµ¬ë²„ì „
â”‚
â”œâ”€â”€ ğŸ”§ í¬ë¡¤ë§ ë„êµ¬ (Serviceë¡œ ì´ë™ í•„ìš”)
â”‚   â”œâ”€â”€ crawl_session_managed.py   # SiteCrawler í´ë˜ìŠ¤
â”‚   â””â”€â”€ crawl_two_step.py          # TwoStepCrawler í´ë˜ìŠ¤
â”‚
â”œâ”€â”€ ğŸ§ª í…ŒìŠ¤íŠ¸ íŒŒì¼
â”‚   â”œâ”€â”€ test_js_snippet.py
â”‚   â”œâ”€â”€ test_js_snippet_browser.py
â”‚   â”œâ”€â”€ test_image_downloader.py
â”‚   â””â”€â”€ test_font_color_utils.py
â”‚
â”œâ”€â”€ âš™ï¸ ì„¤ì •/ìœ í‹¸ë¦¬í‹°
â”‚   â”œâ”€â”€ setup_env.py          # í™˜ê²½ ì„¤ì •
â”‚   â””â”€â”€ paths.py              # ê²½ë¡œ ìœ í‹¸
â”‚
â””â”€â”€ ğŸ—‘ï¸ êµ¬ë²„ì „/í…ŒìŠ¤íŠ¸
    â”œâ”€â”€ xlcrawl2_old.py
    â”œâ”€â”€ xlcrawl.py
    â””â”€â”€ 0.TEST.py
```

---

## ğŸ¯ ì¬êµ¬ì¡°í™” ëª©í‘œ

### ë¶„ë¥˜ ê¸°ì¤€
1. **Main Scripts** (`scripts/`): ì‚¬ìš©ìê°€ ì§ì ‘ ì‹¤í–‰í•˜ëŠ” ì—”íŠ¸ë¦¬í¬ì¸íŠ¸
2. **Services** (`modules/*/services/`): ë¹„ì¦ˆë‹ˆìŠ¤ ë¡œì§, ì¬ì‚¬ìš© ê°€ëŠ¥í•œ í´ë˜ìŠ¤
3. **Adapters** (`modules/*/adapters/`): ì™¸ë¶€ ì‹œìŠ¤í…œ ì—°ë™ (Excel, WebDriver ë“±)
4. **Utils** (`modules/*/utils/`): í—¬í¼ í•¨ìˆ˜, ìœ í‹¸ë¦¬í‹°
5. **Tests** (`tests/`): ë‹¨ìœ„ í…ŒìŠ¤íŠ¸, í†µí•© í…ŒìŠ¤íŠ¸

---

## ğŸ“¦ ì¬êµ¬ì¡°í™” ê³„íš

### Phase 1: í¬ë¡¤ë§ ê´€ë ¨ ì¬êµ¬ì¡°í™”

#### 1ï¸âƒ£ **Service ë¶„ë¦¬**

**ì´ë™: `crawl_session_managed.py` â†’ `modules/crawl_utils/services/site_crawler.py`**
```python
# modules/crawl_utils/services/site_crawler.py
"""
ì‚¬ì´íŠ¸ë³„ í¬ë¡¤ë§ Service

ì—­í• : ì‚¬ì´íŠ¸ë³„ ê²€ìƒ‰/ìƒì„¸ í¬ë¡¤ë§ ë¡œì§
ì˜ì¡´ì„±: CrawlPipeline, create_webdriver
ì¬ì‚¬ìš©: ì—¬ëŸ¬ ë©”ì¸ ìŠ¤í¬ë¦½íŠ¸ì—ì„œ í˜¸ì¶œ ê°€ëŠ¥
"""

class SiteCrawler:
    """ì‚¬ì´íŠ¸ë³„ í¬ë¡¤ë§ Service"""
    
    def crawl_search(self, query: str, max_pages: int) -> Path:
        """Step 1: ê²€ìƒ‰ ê²°ê³¼ í¬ë¡¤ë§"""
        
    def crawl_detail(self, url: str) -> Dict:
        """Step 2: ìƒì„¸ í˜ì´ì§€ í¬ë¡¤ë§"""
        
    def crawl_detail_batch(self, urls: List[str]):
        """Step 2: ë°°ì¹˜ í¬ë¡¤ë§"""
```

**ì´ë™: `manual_filter_urls()` â†’ `modules/crawl_utils/utils/filter_utils.py`**
```python
# modules/crawl_utils/utils/filter_utils.py
"""
í¬ë¡¤ë§ ê²°ê³¼ í•„í„°ë§ ìœ í‹¸ë¦¬í‹°

ì—­í• : ê²€ìƒ‰ ê²°ê³¼ ìˆ˜ë™ ì„ íƒ, URL í•„í„°ë§
"""

def manual_filter_urls(search_output_dir: Path) -> List[str]:
    """ìˆ˜ë™ í•„í„°ë§ UI"""

def filter_by_price(urls: List[str], min_price: float, max_price: float) -> List[str]:
    """ê°€ê²© í•„í„°ë§"""
```

#### 2ï¸âƒ£ **Adapter ë¶„ë¦¬**

**ì‹ ê·œ: `modules/xl_utils/adapters/crawl_adapter.py`**
```python
# modules/xl_utils/adapters/crawl_adapter.py
"""
Excel â†” Crawl ì—°ë™ Adapter

ì—­í• : Excelì—ì„œ URL ì¶”ì¶œ, ê²°ê³¼ë¥¼ Excelì— ì €ì¥
ì˜ì¡´ì„±: XlController, SiteCrawler
"""

class XlCrawlAdapter:
    """Excel + í¬ë¡¤ë§ í†µí•©"""
    
    def extract_urls_from_excel(self, sheet: str, column: str) -> List[str]:
        """Excelì—ì„œ URL ì¶”ì¶œ"""
    
    def update_download_status(self, urls: List[str], status: str):
        """ë‹¤ìš´ë¡œë“œ ìƒíƒœ ì—…ë°ì´íŠ¸"""
```

#### 3ï¸âƒ£ **ë©”ì¸ ìŠ¤í¬ë¦½íŠ¸ ê°„ì†Œí™”**

**ê°„ì†Œí™”: `scripts/xlcrawl2.py`**
```python
# scripts/xlcrawl2.py (ë©”ì¸ ìŠ¤í¬ë¦½íŠ¸)
"""
Excel í¬ë¡¤ë§ ìë™í™” ë©”ì¸

ì‚¬ìš©ë²•:
    python scripts/xlcrawl2.py
"""

from crawl_utils.services.site_crawler import SiteCrawler
from xl_utils.adapters.crawl_adapter import XlCrawlAdapter

def main():
    # 1. Excelì—ì„œ URL ì¶”ì¶œ
    adapter = XlCrawlAdapter("configs/excel.yaml")
    urls = adapter.extract_urls_from_excel("Sheet1", "URL")
    
    # 2. í¬ë¡¤ë§
    crawler = SiteCrawler("taobao")
    for url in urls:
        crawler.crawl_detail(url)
    
    # 3. Excel ì—…ë°ì´íŠ¸
    adapter.update_download_status(urls, "ì™„ë£Œ")

if __name__ == "__main__":
    main()
```

---

### Phase 2: OTO ê´€ë ¨ ì¬êµ¬ì¡°í™”

#### 1ï¸âƒ£ **Service ë¶„ë¦¬**

**ì´ë™: `scripts/xloto.py` í´ë˜ìŠ¤ë“¤ â†’ `modules/image_utils/services/`**
```python
# modules/image_utils/services/oto_processor.py
"""
ì´ë¯¸ì§€ OTO ì²˜ë¦¬ Service

ì—­í• : ì´ë¯¸ì§€ OCR, ë²ˆì—­, ì˜¤ë²„ë ˆì´
"""

class ImageOTOProcessor:
    def process_oto(self, image_path: Path, config: OTOConfig) -> Path:
        """OTO ì „ì²´ íŒŒì´í”„ë¼ì¸"""

# modules/image_utils/services/casno_extractor.py
class CASNoExtractor:
    def extract_casno(self, text: str) -> Optional[str]:
        """CAS ë²ˆí˜¸ ì¶”ì¶œ"""
```

#### 2ï¸âƒ£ **Adapter ë¶„ë¦¬**

**ì´ë™: `modules/xl_utils/adapters/oto_adapter.py`**
```python
# modules/xl_utils/adapters/oto_adapter.py
"""
Excel â†” OTO ì—°ë™ Adapter

ì—­í• : Excelì—ì„œ ì´ë¯¸ì§€ ê²½ë¡œ ì½ê¸°, ê²°ê³¼ ì €ì¥
"""

class XlOTOAdapter:
    def get_image_paths(self, sheet: str) -> List[Path]:
        """Excelì—ì„œ ì´ë¯¸ì§€ ê²½ë¡œ ì¶”ì¶œ"""
    
    def save_oto_results(self, results: List[Dict]):
        """OTO ê²°ê³¼ë¥¼ Excelì— ì €ì¥"""
```

#### 3ï¸âƒ£ **ë©”ì¸ ìŠ¤í¬ë¦½íŠ¸ ê°„ì†Œí™”**

**ê°„ì†Œí™”: `scripts/xloto.py`**
```python
# scripts/xloto.py (ë©”ì¸ ìŠ¤í¬ë¦½íŠ¸)
"""
Excel OTO ìë™í™” ë©”ì¸
"""

from image_utils.services.oto_processor import ImageOTOProcessor
from xl_utils.adapters.oto_adapter import XlOTOAdapter

def main():
    # 1. Excelì—ì„œ ì´ë¯¸ì§€ ê²½ë¡œ ì¶”ì¶œ
    adapter = XlOTOAdapter("configs/excel.yaml")
    image_paths = adapter.get_image_paths("Sheet1")
    
    # 2. OTO ì²˜ë¦¬
    processor = ImageOTOProcessor()
    results = []
    for path in image_paths:
        result = processor.process_oto(path, config)
        results.append(result)
    
    # 3. Excelì— ì €ì¥
    adapter.save_oto_results(results)

if __name__ == "__main__":
    main()
```

---

### Phase 3: í…ŒìŠ¤íŠ¸ íŒŒì¼ ì •ë¦¬

#### ì´ë™ ê³„íš:
```
scripts/test_*.py â†’ tests/integration/
```

#### ìƒˆë¡œìš´ êµ¬ì¡°:
```
tests/
â”œâ”€â”€ unit/                      # ë‹¨ìœ„ í…ŒìŠ¤íŠ¸
â”‚   â”œâ”€â”€ test_xl_utils.py
â”‚   â”œâ”€â”€ test_crawl_utils.py
â”‚   â””â”€â”€ test_image_utils.py
â”‚
â”œâ”€â”€ integration/               # í†µí•© í…ŒìŠ¤íŠ¸
â”‚   â”œâ”€â”€ test_xlcrawl_workflow.py      # xlcrawl2.py í…ŒìŠ¤íŠ¸
â”‚   â”œâ”€â”€ test_xloto_workflow.py        # xloto.py í…ŒìŠ¤íŠ¸
â”‚   â”œâ”€â”€ test_js_snippet.py            # JS ì¶”ì¶œ í…ŒìŠ¤íŠ¸
â”‚   â””â”€â”€ test_image_downloader.py      # ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ í…ŒìŠ¤íŠ¸
â”‚
â””â”€â”€ manual/                    # ìˆ˜ë™ í…ŒìŠ¤íŠ¸
    â”œâ”€â”€ test_js_snippet_browser.py
    â””â”€â”€ test_font_color_utils.py
```

---

## ğŸ“ ìµœì¢… ë””ë ‰í† ë¦¬ êµ¬ì¡°

```
m:\CALife\CAShop - êµ¬ë§¤ëŒ€í–‰\_code/

â”œâ”€â”€ ğŸ“‚ scripts/                        # ğŸš€ ë©”ì¸ ì—”íŠ¸ë¦¬í¬ì¸íŠ¸ë§Œ
â”‚   â”œâ”€â”€ xlcrawl2.py                   # Excel í¬ë¡¤ë§ ë©”ì¸
â”‚   â”œâ”€â”€ xloto.py                      # OTO ë©”ì¸
â”‚   â”œâ”€â”€ setup_env.py                  # í™˜ê²½ ì„¤ì •
â”‚   â””â”€â”€ [ì‚­ì œ ì˜ˆì •]
â”‚       â”œâ”€â”€ crawl_session_managed.py  â†’ modules/crawl_utils/services/
â”‚       â”œâ”€â”€ crawl_two_step.py         â†’ modules/crawl_utils/services/
â”‚       â”œâ”€â”€ test_*.py                 â†’ tests/integration/
â”‚       â””â”€â”€ *_old.py, 0.TEST.py       â†’ ì‚­ì œ
â”‚
â”œâ”€â”€ ğŸ“‚ modules/                        # ğŸ“¦ ì¬ì‚¬ìš© ê°€ëŠ¥ ëª¨ë“ˆ
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ“‚ crawl_utils/
â”‚   â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”‚   â”œâ”€â”€ site_crawler.py       # SiteCrawler (ì´ë™)
â”‚   â”‚   â”‚   â””â”€â”€ pipeline.py           # CrawlPipeline (ê¸°ì¡´)
â”‚   â”‚   â”œâ”€â”€ adapters/
â”‚   â”‚   â”‚   â””â”€â”€ [ì‹ ê·œ í•„ìš”ì‹œ ì¶”ê°€]
â”‚   â”‚   â””â”€â”€ utils/
â”‚   â”‚       â”œâ”€â”€ filter_utils.py       # manual_filter_urls (ì´ë™)
â”‚   â”‚       â””â”€â”€ anti_detection.py     # ì°¸ê³ ìš© (ê¸°ì¡´)
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ“‚ xl_utils/
â”‚   â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”‚   â””â”€â”€ controller.py         # XlController (ê¸°ì¡´)
â”‚   â”‚   â”œâ”€â”€ adapters/                 # ğŸ†• ì‹ ê·œ
â”‚   â”‚   â”‚   â”œâ”€â”€ crawl_adapter.py      # Excel â†” Crawl
â”‚   â”‚   â”‚   â””â”€â”€ oto_adapter.py        # Excel â†” OTO
â”‚   â”‚   â””â”€â”€ utils/
â”‚   â”‚       â””â”€â”€ ...
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ“‚ image_utils/
â”‚   â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”‚   â”œâ”€â”€ oto_processor.py      # ImageOTOProcessor (ì´ë™)
â”‚   â”‚   â”‚   â”œâ”€â”€ casno_extractor.py    # CASNoExtractor (ì´ë™)
â”‚   â”‚   â”‚   â””â”€â”€ image_downloader.py   # (ê¸°ì¡´)
â”‚   â”‚   â”œâ”€â”€ adapters/
â”‚   â”‚   â”‚   â””â”€â”€ ocr_adapter.py        # OCR ì—°ë™
â”‚   â”‚   â””â”€â”€ utils/
â”‚   â”‚       â””â”€â”€ ...
â”‚   â”‚
â”‚   â””â”€â”€ ğŸ“‚ translate_utils/
â”‚       â”œâ”€â”€ services/
â”‚       â”‚   â””â”€â”€ translator.py         # (ê¸°ì¡´)
â”‚       â””â”€â”€ adapters/
â”‚           â””â”€â”€ ...
â”‚
â”œâ”€â”€ ğŸ“‚ tests/                          # ğŸ§ª í…ŒìŠ¤íŠ¸
â”‚   â”œâ”€â”€ unit/
â”‚   â”œâ”€â”€ integration/                  # test_*.py ì´ë™
â”‚   â””â”€â”€ manual/
â”‚
â””â”€â”€ ğŸ“‚ configs/                        # âš™ï¸ ì„¤ì •
    â”œâ”€â”€ excel.yaml
    â”œâ”€â”€ xlcrawl.yaml
    â”œâ”€â”€ firefox_taobao.yaml
    â””â”€â”€ ...
```

---

## ğŸ”§ ë¦¬íŒ©í† ë§ ìˆœì„œ

### Step 1: í¬ë¡¤ë§ Service ë¶„ë¦¬ (ìš°ì„ ìˆœìœ„ ë†’ìŒ)
1. `crawl_session_managed.py` â†’ `modules/crawl_utils/services/site_crawler.py`
2. `manual_filter_urls()` â†’ `modules/crawl_utils/utils/filter_utils.py`
3. `scripts/xlcrawl2.py` ê°„ì†Œí™”

### Step 2: Excel Adapter ìƒì„±
1. `modules/xl_utils/adapters/crawl_adapter.py` ìƒì„±
2. `extract_urls_from_dataframe()`, `update_download_column()` ì´ë™
3. `scripts/xlcrawl2.py`ì—ì„œ Adapter ì‚¬ìš©

### Step 3: OTO Service ë¶„ë¦¬
1. `ImageOTOProcessor` â†’ `modules/image_utils/services/oto_processor.py`
2. `CASNoExtractor` â†’ `modules/image_utils/services/casno_extractor.py`
3. `modules/xl_utils/adapters/oto_adapter.py` ìƒì„±
4. `scripts/xloto.py` ê°„ì†Œí™”

### Step 4: í…ŒìŠ¤íŠ¸ íŒŒì¼ ì´ë™
1. `scripts/test_*.py` â†’ `tests/integration/`
2. `tests/` êµ¬ì¡°í™”

### Step 5: ì •ë¦¬
1. `*_old.py`, `0.TEST.py` ì‚­ì œ
2. `__init__.py` ì—…ë°ì´íŠ¸
3. Import ê²½ë¡œ ìˆ˜ì •
4. ë¬¸ì„œ ì—…ë°ì´íŠ¸

---

## ğŸ“ ë§ˆì´ê·¸ë ˆì´ì…˜ ê°€ì´ë“œ

### Before (í˜„ì¬)
```python
# scripts/xlcrawl2.py (270ì¤„)
def load_paths_config(): ...
def get_config_paths(): ...
def extract_urls_from_dataframe(): ...
def process_crawling(): ...
def update_download_column(): ...
def main(): ...
```

### After (ëª©í‘œ)
```python
# scripts/xlcrawl2.py (50ì¤„)
from crawl_utils.services.site_crawler import SiteCrawler
from xl_utils.adapters.crawl_adapter import XlCrawlAdapter

def main():
    adapter = XlCrawlAdapter()
    urls = adapter.extract_urls()
    
    crawler = SiteCrawler("taobao")
    crawler.crawl_detail_batch(urls)
    
    adapter.update_status(urls, "ì™„ë£Œ")
```

---

## âœ… ë¦¬íŒ©í† ë§ íš¨ê³¼

### 1ï¸âƒ£ **ëª…í™•í•œ ì—­í•  ë¶„ë¦¬**
- **Scripts**: ì‹¤í–‰ë§Œ (50ì¤„ ì´ë‚´)
- **Services**: ë¹„ì¦ˆë‹ˆìŠ¤ ë¡œì§ (ì¬ì‚¬ìš© ê°€ëŠ¥)
- **Adapters**: ì™¸ë¶€ ì—°ë™ (Excel, WebDriver)
- **Utils**: í—¬í¼ í•¨ìˆ˜

### 2ï¸âƒ£ **ì¬ì‚¬ìš©ì„± í–¥ìƒ**
- `SiteCrawler`ë¥¼ ì—¬ëŸ¬ ìŠ¤í¬ë¦½íŠ¸ì—ì„œ ì‚¬ìš© ê°€ëŠ¥
- `XlCrawlAdapter`ë¥¼ ë‹¤ë¥¸ ì›Œí¬í”Œë¡œìš°ì—ì„œ ì¬ì‚¬ìš©

### 3ï¸âƒ£ **í…ŒìŠ¤íŠ¸ ìš©ì´ì„±**
- Service ë‹¨ìœ„ í…ŒìŠ¤íŠ¸ ê°€ëŠ¥
- Adapter ëª¨í‚¹ ê°€ëŠ¥
- í†µí•© í…ŒìŠ¤íŠ¸ ë¶„ë¦¬

### 4ï¸âƒ£ **ìœ ì§€ë³´ìˆ˜ì„±**
- íŒŒì¼ ìœ„ì¹˜ë¡œ ì—­í•  íŒŒì•… ê°€ëŠ¥
- Import ê²½ë¡œë¡œ ì˜ì¡´ì„± ëª…í™•
- ë³€ê²½ ì˜í–¥ ë²”ìœ„ ì œí•œ

---

## ğŸš€ ì‹¤í–‰ ê³„íš

**ì§€ê¸ˆ ë°”ë¡œ ì‹œì‘í•˜ì‹œê² ìŠµë‹ˆê¹Œ?**

1. âœ… Step 1 ì‹¤í–‰: í¬ë¡¤ë§ Service ë¶„ë¦¬
2. â­ï¸ Step 2 ëŒ€ê¸°: Excel Adapter ìƒì„±
3. â­ï¸ Step 3 ëŒ€ê¸°: OTO Service ë¶„ë¦¬
4. â­ï¸ Step 4 ëŒ€ê¸°: í…ŒìŠ¤íŠ¸ ì´ë™
5. â­ï¸ Step 5 ëŒ€ê¸°: ì •ë¦¬

ì–´ëŠ ë‹¨ê³„ë¶€í„° ì§„í–‰í• ê¹Œìš”?
